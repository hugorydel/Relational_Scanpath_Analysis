{
	"150472": {
		"cue": "pizza",
		"story": "Two women lean in with open mouths toward a large slice of pizza on a paper plate, each taking a bite from it.",
		"encoding_questions": [
			{
				"question": "How many women are in the scene?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			},
			{
				"question": "Where is the pizza slice located?",
				"options": ["on paper plate", "in pizza box", "on metal tray", "on table"],
				"answer": "on paper plate"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"women bite pizza slice",
					"women photograph pizza slice",
					"women cut large pizza",
					"women carry pizza boxes"
				],
				"answer": "women bite pizza slice"
			}
		]
	},
	"2344622": {
		"cue": "cat",
		"story": "A person is typing on a keyboard. A cat is resting its head next to the person's arm on top of a blue blanket, near the keyboard.",
		"encoding_questions": [
			{
				"question": "Where is the cat positioned relative to other scene elements?",
				"options": [
					"next to keyboard",
					"on keyboard",
					"under blanket",
					"on person's arm"
				],
				"answer": "next to keyboard"
			},
			{
				"question": "What is the cat resting its head on?",
				"options": ["person's arm", "keyboard edge", "plush toy", "blue blanket"],
				"answer": "blue blanket"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"cat lies on blanket",
					"cat lies on person's arm",
					"cat paws at keyboard",
					"cat paws at blanket"
				],
				"answer": "cat lies on blanket"
			}
		]
	},
	"2345035": {
		"cue": "football",
		"story": "A girl in a blue jersey runs towards a football while a girl in a white jersey runs alongside and challenges her for it.",
		"encoding_questions": [
			{
				"question": "Who runs toward the football in the scene?",
				"options": ["girls", "boys", "men", "girl and boy"],
				"answer": "girls"
			},
			{
				"question": "What are the girls doing with the ball?",
				"options": ["chasing", "kicking", "catching", "bouncing"],
				"answer": "chasing"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"girls run toward football",
					"man kicks football into goal",
					"boy slides for football",
					"goalkeeper catches football"
				],
				"answer": "girls run toward football"
			}
		]
	},
	"2347025": {
		"cue": "umbrella",
		"story": "A woman carries a baby on her back. The baby holds up a pink umbrella above them.",
		"encoding_questions": [
			{
				"question": "Who is holding the umbrella in the scene?",
				"options": ["baby", "woman", "man", "girl"],
				"answer": "baby"
			},
			{
				"question": "Where is the baby in relation to the mother?",
				"options": ["on back", "in arms", "sitting on shoulders", "next to her"],
				"answer": "on back"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"baby holds onto umbrella",
					"woman holds umbrella over baby",
					"baby drags pink umbrella",
					"baby lies under umbrella"
				],
				"answer": "baby holds onto umbrella"
			}
		]
	},
	"2347400": {
		"cue": "wine",
		"story": "Two men sit on a couch, each holding a wine glass near their faces and smelling the wine.",
		"encoding_questions": [
			{
				"question": "What are the men doing with the wine?",
				"options": ["smelling", "sipping", "pouring", "clinking"],
				"answer": "smelling"
			},
			{
				"question": "What are the men sitting on in the scene?",
				"options": ["couch", "bench", "table", "chairs"],
				"answer": "couch"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"men smell wine glasses",
					"men clink wine glasses",
					"men sip from wine glasses",
					"men grab wine bottles"
				],
				"answer": "men smell wine glasses"
			}
		]
	},
	"2348899": {
		"cue": "tie",
		"story": "A woman touches/holds the seated man's striped tie while he smiles. A man in a suit leans in and gestures toward the seated man during their conversation.",
		"encoding_questions": [
			{
				"question": "What is the woman doing in the scene?",
				"options": [
					"touching striped tie",
					"showing striped tie to man",
					"presenting striped tie as a gift",
					"folding a striped tie"
				],
				"answer": "touching striped tie"
			},
			{
				"question": "From your point of view, where is the woman in the scene?",
				"options": ["on the left", "on the right", "at the back", "up front"],
				"answer": "on the right"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"woman touches man's striped tie",
					"man holds his striped tie",
					"man ties another man's striped tie",
					"woman gives man a striped tie"
				],
				"answer": "woman touches man's striped tie"
			}
		]
	},
	"2349475": {
		"cue": "blender",
		"story": "A man uses a bike to power a blender while a woman holds the lid of the blender filled with liquid.",
		"encoding_questions": [
			{
				"question": "How is the woman securing the blender?",
				"options": [
					"holding the blender lid",
					"holding the blender base",
					"holding the blender glass",
					"holding the blender cord"
				],
				"answer": "holding the blender lid"
			},
			{
				"question": "From your point of view, where is the man who's powering the blender?",
				"options": [
					"behind it",
					"in front of it",
					"to the left of it",
					"to the right of it"
				],
				"answer": "to the left of it"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"woman holds onto blender",
					"woman presses blender button",
					"woman opens blender lid",
					"woman cranks blender handle"
				],
				"answer": "woman holds onto blender"
			}
		]
	},
	"2350974": {
		"cue": "drink",
		"story": "A child drinks from a bottle while standing next to a red car. The child rests a hand on the car door.",
		"encoding_questions": [
			{
				"question": "What is the child's hand touching?",
				"options": ["red car", "red motorcycle", "grey car", "grey motorcycle"],
				"answer": "red car"
			},
			{
				"question": "What is the child in between?",
				"options": [
					"grey car and red motorcycle",
					"blue motorcycle and red motorcycle",
					"red car and blue motorcycle",
					"blue car and red car"
				],
				"answer": "red car and blue motorcycle"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"child drinks beside car",
					"adult drinks beside bus",
					"child drinks beside stroller",
					"adult drinks beside train"
				],
				"answer": "child drinks beside car"
			}
		]
	},
	"2356125": {
		"cue": "luggage",
		"story": "Two uniformed women push/move large luggage along an airport conveyor belt, while two other uniformed staff stand nearby.",
		"encoding_questions": [
			{
				"question": "Where is the luggage being moved to?",
				"options": [
					"onto conveyor belt",
					"onto baggage cart",
					"onto xray",
					"off of xray"
				],
				"answer": "onto conveyor belt"
			},
			{
				"question": "How many uniformed staff are moving the luggage?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"staff load luggage onto a conveyor belt",
					"staff load luggage into an xray",
					"staff load luggage onto a cart",
					"staff tag luggage at a counter"
				],
				"answer": "staff load luggage onto a conveyor belt"
			}
		]
	},
	"2360001": {
		"cue": "clock",
		"story": "Two workers are lifting a large round clock onto a building facade, with one of them steadying it while the other attaches it to the bracket and weaves through a cable.",
		"encoding_questions": [
			{
				"question": "Where are the men?",
				"options": ["on scaffold", "on ground", "on balcony", "on roof edge"],
				"answer": "on scaffold"
			},
			{
				"question": "What are the workers doing to the clock?",
				"options": ["raising it", "wiping it", "painting it", "measuring it"],
				"answer": "raising it"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"workers lift large clock",
					"workers wipe large clock face",
					"workers paint old clock",
					"workers raise ladder up to clock"
				],
				"answer": "workers lift large clock"
			}
		]
	},
	"2362277": {
		"cue": "frisbee",
		"story": "A player in white runs while attempting to throw a frisbee. A player in red closely blocks him from throwing the frisbee.",
		"encoding_questions": [
			{
				"question": "How are the frisbee defender's arms positioned?",
				"options": [
					"both high above head",
					"both below waist",
					"both out to the side",
					"one above ahead; the other below waist"
				],
				"answer": "both out to the side"
			},
			{
				"question": "From your point of view, on which side is the frisbee thrower in the scene?",
				"options": [
					"on the left",
					"on the right",
					"behind defender",
					"in front of defender"
				],
				"answer": "on the left"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"player throws a frisbee",
					"player runs towards frisbee",
					"player catches frisbee overhead",
					"player catches frisbee at waist"
				],
				"answer": "player throws a frisbee"
			}
		]
	},
	"2362704": {
		"cue": "bears",
		"story": "Two bears are eating pieces of a pumpkin on the ground. One bear has its face in the hollow pumpkin while the other eats a chunk nearby.",
		"encoding_questions": [
			{
				"question": "How many bears are in the scene?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			},
			{
				"question": "What are the bears doing with the pumpkin?",
				"options": ["eating", "sniffing", "pawing", "fighting over"],
				"answer": "eating"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"bears eat pumpkin",
					"bears sniff pumpkin",
					"bears paw at pumpkin",
					"bears fight over pumpkin"
				],
				"answer": "bears eat pumpkin"
			}
		]
	},
	"2363971": {
		"cue": "petting",
		"story": "A woman pets a large dog in the foreground while another woman in a chair holds a child upside down on her lap. A man also pets the dog in the foreground. The scene takes place indoors.",
		"encoding_questions": [
			{
				"question": "Where does the petting occur in the scene?",
				"options": [
					"indoors (living room)",
					"outdoors (unclear)",
					"outdoors (street)",
					"outdoors (park)"
				],
				"answer": "indoors (living room)"
			},
			{
				"question": "What is the seated woman (in background) doing with the child?",
				"options": [
					"holding it upside down",
					"feeding it from bowl",
					"hugging it",
					"reading a book to it"
				],
				"answer": "holding it upside down"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"woman pets dog indoors",
					"woman pets cat outside",
					"child pets horse outside",
					"child pets dog indoors"
				],
				"answer": "woman pets dog indoors"
			}
		]
	},
	"2366915": {
		"cue": "surfer",
		"story": "Two surfers ride along the same breaking wave as water sprays behind and around them.",
		"encoding_questions": [
			{
				"question": "How many surfers are riding the wave?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			},
			{
				"question": "How large is the wave relative to the surfers?",
				"options": [
					"half as tall",
					"as tall as them",
					"twice as tall",
					"three times as tall"
				],
				"answer": "as tall as them"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"two surfers ride a wave",
					"two surfers paddle toward wave",
					"one surfer rides a wave",
					"two surfers walk toward wave"
				],
				"answer": "two surfers ride a wave"
			}
		]
	},
	"2367132": {
		"cue": "video game",
		"story": "Two men are playing a video game while holding motion controllers and moving their arms.",
		"encoding_questions": [
			{
				"question": "How many men are playing in the scene?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			},
			{
				"question": "From THEIR point of view, in which hand(s) do the men hold the controllers?",
				"options": [
					"in right hand",
					"in left hand",
					"in both hands",
					"neither hand (on wrists)"
				],
				"answer": "in both hands"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"men play video game with motion controllers",
					"men watch video game on TV",
					"men play video game with xbox controllers",
					"men play board game at table"
				],
				"answer": "men play video game with motion controllers"
			}
		]
	},
	"2369373": {
		"cue": "chef",
		"story": "A chef places a pizza into a wood-fired oven, which has the appearance of a Greek god's open mouth.",
		"encoding_questions": [
			{
				"question": "What is the appearance of the oven?",
				"options": ["open mouth", "stone arch", "metal box", "brick dome"],
				"answer": "open mouth"
			},
			{
				"question": "What is the chef placing into the oven?",
				"options": ["bread", "steak", "vegetable tray", "pizza"],
				"answer": "pizza"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"chef loads pizza into oven",
					"chef loads bread into oven",
					"chef pulls tray from oven",
					"chef stokes oven flames"
				],
				"answer": "chef loads pizza into oven"
			}
		]
	},
	"2370664": {
		"cue": "donuts",
		"story": "Two men and a woman are taking bites of donuts. They are close together outdoors, holding the donuts up to their mouths.",
		"encoding_questions": [
			{
				"question": "How many donuts are in the scene?",
				"options": ["two", "three", "four", "five"],
				"answer": "three"
			},
			{
				"question": "Where are the people located in the scene?",
				"options": ["street", "living room", "restaurant", "kitchen"],
				"answer": "street"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"people bite into donuts",
					"people dip donuts in coffee",
					"man offers donut to woman",
					"people hold donuts over eyes"
				],
				"answer": "people bite into donuts"
			}
		]
	},
	"2371471": {
		"cue": "motorcycle",
		"story": "Two motorcyclists are airborne on dirt bikes inside a building, performing jumps above a ramp.",
		"encoding_questions": [
			{
				"question": "Which of the motorcyclists is performing a handstand?",
				"options": ["one up front", "one at the back", "both", "neither"],
				"answer": "one up front"
			},
			{
				"question": "What is nearest to the motorcyclists?",
				"options": ["dirt ramp", "asphalt road", "grassy ground", "concrete ramp"],
				"answer": "dirt ramp"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"motorcyclists jump over ramp",
					"motorcyclists drive on road",
					"motorcyclists pop a wheelie",
					"motorcyclists speed across road"
				],
				"answer": "motorcyclists jump over ramp"
			}
		]
	},
	"2374670": {
		"cue": "truck",
		"story": "A red truck sprays water onto a dirt road through nozzles at the back. A man is climbing on the back of the truck while it operates.",
		"encoding_questions": [
			{
				"question": "What vehicle sprays water in the scene?",
				"options": ["red truck", "red tractor", "grey van", "grey tractor"],
				"answer": "red truck"
			},
			{
				"question": "What is the truck spraying?",
				"options": ["water", "sand", "fertilizer", "asphalt"],
				"answer": "water"
			},
			{
				"question": "Where is the (actively moving) man positioned relative to the truck?",
				"options": ["back", "roof", "side", "front"],
				"answer": "back"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"truck sprays water",
					"truck dumps gravel onto road",
					"truck pulls broken car",
					"truck fills water tank"
				],
				"answer": "truck sprays water"
			}
		]
	},
	"2379478": {
		"cue": "milk",
		"story": "Two babies are lying on a bed, each drinking from a milk bottle.",
		"encoding_questions": [
			{
				"question": "What is the position of the babies?",
				"options": ["lying on bed", "sitting on bed", "lying in crib", "lying on couch"],
				"answer": "lying on bed"
			},
			{
				"question": "In what position are the babies drinking milk?",
				"options": ["lying on stomach", "lying on back", "lying on side", "sitting up"],
				"answer": "lying on back"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"two babies drink from milk bottles",
					"one baby drinks from a milk bottle",
					"one baby reaches for milk bottle",
					"two babies reach for one milk bottle"
				],
				"answer": "two babies drink from milk bottles"
			}
		]
	},
	"2383555": {
		"cue": "boat",
		"story": "A woman sits in a bamboo boat holding a child on her lap. A woman behind her rows the boat through the water.",
		"encoding_questions": [
			{
				"question": "Who is holding the child in the boat?",
				"options": ["woman", "man", "girl", "boy"],
				"answer": "woman"
			},
			{
				"question": "What is the woman at the back doing in the boat?",
				"options": ["rowing", "standing", "sitting", "waving"],
				"answer": "rowing"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"woman holds child on boat",
					"two women row a boat",
					"child sits alone in boat",
					"man steps onto a boat"
				],
				"answer": "woman holds child on boat"
			}
		]
	},
	"2385550": {
		"cue": "tangerines",
		"story": "A boy and a girl each have a tangerine in their mouth and are eating it while facing the camera.",
		"encoding_questions": [
			{
				"question": "Where are the tangerines in the scene?",
				"options": ["in mouths", "in hands", "on head", "in front of eyes"],
				"answer": "in mouths"
			},
			{
				"question": "From your point of view, where is the boy in the scene?",
				"options": ["on the left", "on the right", "in the back", "in the front"],
				"answer": "on the left"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"children have tangerines in mouths",
					"children peel tangerines",
					"children hold tangerines in hands",
					"children pick tangerines from tree"
				],
				"answer": "children have tangerines in mouths"
			}
		]
	},
	"2386442": {
		"cue": "teeth",
		"story": "A woman, a child, and a man are each brushing their teeth with toothbrushes. They are facing the camera while brushing. The man is wearing a purple shirt, the woman is wearing a striped shirt, while the child is wearing a pink checkered shirt.",
		"encoding_questions": [
			{
				"question": "Who is brushing their teeth in the scene?",
				"options": [
					"man and two children",
					"man and woman",
					"child and two women",
					"man, woman, and child"
				],
				"answer": "man, woman, and child"
			},
			{
				"question": "From your point of view, where is the child in the scene?",
				"options": ["in the middle", "on the left", "on the right", "at the back"],
				"answer": "in the middle"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"family brushes teeth together",
					"child flosses teeth carefully",
					"family checks teeth in mirror",
					"woman brushes a child's teeth"
				],
				"answer": "family brushes teeth together"
			}
		]
	},
	"2387122": {
		"cue": "polar bear",
		"story": "A polar bear swims in the water and presses against the enclosure glass while a woman on the other side takes a photo of it.",
		"encoding_questions": [
			{
				"question": "Where is the polar bear located in the scene?",
				"options": ["in water", "on ice", "on rocks", "on sand"],
				"answer": "in water"
			},
			{
				"question": "What is the polar bear doing next to the enclosure edge?",
				"options": [
					"pressing on glass enclosure",
					"swimming away from glass enclosure",
					"sitting on snowy ground",
					"diving underwater"
				],
				"answer": "pressing on glass enclosure"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"polar bear presses on glass",
					"polar bear swims away from glass",
					"polar bear sits on snowy ground",
					"polar bear dives underwater"
				],
				"answer": "polar bear presses on glass"
			}
		]
	},
	"2397102": {
		"cue": "cake",
		"story": "A woman and a man are cutting a decorated wedding cake together while the man holds a bottle in his other hand.",
		"encoding_questions": [
			{
				"question": "What are the couple doing with the cake?",
				"options": [
					"cutting it",
					"feeding each other",
					"posing next to it",
					"serving it"
				],
				"answer": "cutting it"
			},
			{
				"question": "What is the man holding besides the cake knife?",
				"options": ["beer bottle", "paper plate", "present", "wine glass"],
				"answer": "beer bottle"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"couple cuts cake together",
					"couple feeds each other cake",
					"couple poses with wedding cake",
					"couple kisses beside cake"
				],
				"answer": "couple cuts cake together"
			}
		]
	},
	"2401636": {
		"cue": "baby",
		"story": "A cat leans toward and sniffs a baby sitting beside it. A woman holds the cat and baby close while watching the baby.",
		"encoding_questions": [
			{
				"question": "Who is looking at the cat in the scene?",
				"options": ["baby", "woman", "man", "girl"],
				"answer": "baby"
			},
			{
				"question": "What is the mom holding in her arms?",
				"options": ["baby", "dog and cat", "baby and cat", "baby and dog"],
				"answer": "baby and cat"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"baby looks at cat",
					"cat sleeps beside baby",
					"cat licks woman's hand",
					"woman raises up cat"
				],
				"answer": "baby looks at cat"
			}
		]
	},
	"2411268": {
		"cue": "apple",
		"story": "A child reaches up to pick a green apple from a tree while holding a red bag for collecting fruit.",
		"encoding_questions": [
			{
				"question": "What is the child holding while picking fruit?",
				"options": ["bag", "bucket", "box", "basket"],
				"answer": "bag"
			},
			{
				"question": "Where is the fruit branch relative to the child?",
				"options": ["above head", "at head level", "below head", "near ground"],
				"answer": "above head"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"child picks apple from tree",
					"child bites into apple",
					"child picks apple up from the ground",
					"child puts apple into bag"
				],
				"answer": "child picks apple from tree"
			}
		]
	},
	"2412687": {
		"cue": "dog",
		"story": "A person holds out a red frisbee toward a dog. The dog bites onto the frisbee with its mouth.",
		"encoding_questions": [
			{
				"question": "What is the dog biting onto in the scene?",
				"options": ["red frisbee", "red ball", "red boomerang", "red bone"],
				"answer": "red frisbee"
			},
			{
				"question": "What is the main action of the human in the scene?",
				"options": [
					"holding frisbee",
					"throwing frisbee",
					"catching frisbee",
					"picking up frisbee"
				],
				"answer": "holding frisbee"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"dog bites onto frisbee",
					"dog catches frisbee midair",
					"dog ignores offered frisbee",
					"man throws frisbee towards dog"
				],
				"answer": "dog bites onto frisbee"
			}
		]
	},
	"2356991": {
		"cue": "baseball",
		"story": "A player slides headfirst toward a base while another player in a glove catches a thrown ball beside the base.",
		"encoding_questions": [
			{
				"question": "How is the player on the left reaching the base?",
				"options": [
					"sliding headfirst",
					"sliding feetfirst",
					"running towards it",
					"sliding on knees"
				],
				"answer": "sliding headfirst"
			},
			{
				"question": "What is the current action of the gloved player on the base?",
				"options": [
					"catching the ball",
					"dropping the ball",
					"throwing the ball",
					"tagging the runner"
				],
				"answer": "catching the ball"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"player slides headfirst to base",
					"player runs towards base",
					"player slides feetfirst toward base",
					"gloved player holds a ball"
				],
				"answer": "player slides headfirst to base"
			}
		]
	},
	"2385851": {
		"cue": "suitcase",
		"story": "Two men walk along a covered walkway while each carries a large red suitcase.",
		"encoding_questions": [
			{
				"question": "What are the men doing with the suitcases?",
				"options": ["carrying them", "opening them", "stacking them", "pulling them"],
				"answer": "carrying them"
			},
			{
				"question": "Where are the men?",
				"options": [
					"walking under a covered walkway",
					"walking along a train platform",
					"walking in an airport terminal",
					"walking into a hotel lobby"
				],
				"answer": "walking under a covered walkway"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"men carry suitcases on shoulders",
					"men pull suitcases behind them",
					"men stack suitcases on cart",
					"man opens suitcases outside"
				],
				"answer": "men carry suitcases on shoulders"
			}
		]
	},
	"2394020": {
		"cue": "horse ride",
		"story": "Two horseriders are riding horses along the sandy shore beside the water. Both horses are patchy while the riders are wearing cowboy hats. The weather is sunny and the water is calm.",
		"encoding_questions": [
			{
				"question": "Where is the scene taking place?",
				"options": ["along beach", "along stream", "along ocean", "along open field"],
				"answer": "along beach"
			},
			{
				"question": "What are the riders wearing on their heads?",
				"options": ["cowboy hats", "helmets", "baseball caps", "sun hats"],
				"answer": "cowboy hats"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"people ride horses along beach",
					"people ride horses through forest",
					"people ride horses on road",
					"people ride horses through field"
				],
				"answer": "people ride horses along beach"
			}
		]
	},
	"2406346": {
		"cue": "circus",
		"story": "One elephant holds the tail of another elephant, ahead of it, with its trunk. The elephant up front has a star on its back. A handler walks beside the elephants holding a stick and leading the elephants forward.",
		"encoding_questions": [
			{
				"question": "Which elephant is the man/handler closest to?",
				"options": [
					"front elephant",
					"back elephant",
					"both elephants",
					"neither elephant"
				],
				"answer": "back elephant"
			},
			{
				"question": "What is one elephant doing to the other?",
				"options": [
					"holding its tail",
					"touching its trunks",
					"spraying it with water",
					"nothing; its trunk is extended above its head without interaction"
				],
				"answer": "holding its tail"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"circus elephants walk on street",
					"circus elephants perform tricks",
					"circus elephants washed by handler",
					"circus elephants stand on pedestals"
				],
				"answer": "circus elephants walk on street"
			}
		]
	},
	"2408717": {
		"cue": "surfboard",
		"story": "Four surfers walk along the shoreline while carrying their surfboards. Waves roll in front of them as they head down towards the beach.",
		"encoding_questions": [
			{
				"question": "How many surfers are in the scene?",
				"options": ["two", "three", "four", "five"],
				"answer": "four"
			},
			{
				"question": "What are the colors of the surfboards in the scene?",
				"options": [
					"white and red",
					"white and yellow",
					"blue and yellow",
					"red and green"
				],
				"answer": "white and yellow"
			},
			{
				"question": "What is the current state of the surfers? They're...",
				"options": [
					"walking towards water",
					"paddling in water",
					"surfing on a wave",
					"standing on surfboards"
				],
				"answer": "walking towards water"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"surfers walk towards water with surfboards",
					"surfers lie on surfboards",
					"surfers stand on surfboards on the beach",
					"surfers place surfboards into water"
				],
				"answer": "surfers walk towards water with surfboards"
			}
		]
	},
	"2409918": {
		"cue": "elephant",
		"story": "Two men are riding elephants while they are swimming in moderately deep water. One elephant is eating plants with its trunk.",
		"encoding_questions": [
			{
				"question": "What is the elephant on the right doing with its trunk?",
				"options": [
					"eating plants",
					"spraying water",
					"reaching forward",
					"grabbing log"
				],
				"answer": "eating plants"
			},
			{
				"question": "Where are the elephants in the scene?",
				"options": [
					"swimming in water",
					"walking on land",
					"standing in mud",
					"splashing in puddle"
				],
				"answer": "swimming in water"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"elephants swim in water",
					"elephants drink water",
					"elephants splash riders",
					"elephants walk across savannah"
				],
				"answer": "elephants swim in water"
			}
		]
	},
	"2410309": {
		"cue": "laptop",
		"story": "A woman sits on a couch using a laptop on her lap. A baby beside her touches and uses another open laptop.",
		"encoding_questions": [
			{
				"question": "What device is the woman using on the couch?",
				"options": ["laptop", "tablet", "phone", "book"],
				"answer": "laptop"
			},
			{
				"question": "How many open laptops are in the scene?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"woman and baby use laptops",
					"woman closes laptop lid",
					"baby touches laptop mouse",
					"man types on laptop keyboard"
				],
				"answer": "woman and baby use laptops"
			}
		]
	}
}
