{
	"150472": {
		"cue": "pizza",
		"story": "Two women lean in with open mouths toward a large slice of pizza on a paper plate, each taking a bite from it.",
		"encoding_questions": [
			{
				"question": "How many women are in the scene?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			},
			{
				"question": "Where is the pizza slice located?",
				"options": ["in pizza box", "on table", "on metal tray", "on paper plate"],
				"answer": "on paper plate"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"women photograph pizza slice",
					"women carry pizza boxes",
					"women cut large pizza",
					"women bite pizza slice"
				],
				"answer": "women bite pizza slice"
			}
		]
	},
	"2344622": {
		"cue": "cat",
		"story": "A person is typing on a keyboard. A cat is resting its head next to the person's arm on top of a blue blanket, near the keyboard.",
		"encoding_questions": [
			{
				"question": "Where is the cat positioned relative to other scene elements?",
				"options": [
					"on person's arm",
					"next to keyboard",
					"on keyboard",
					"under blanket"
				],
				"answer": "next to keyboard"
			},
			{
				"question": "What is the cat resting its head on?",
				"options": ["plush toy", "blue blanket", "keyboard edge", "person's arm"],
				"answer": "blue blanket"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"cat paws at keyboard",
					"cat paws at blanket",
					"cat lies on blanket",
					"cat lies on person's arm"
				],
				"answer": "cat lies on blanket"
			}
		]
	},
	"2345035": {
		"cue": "football",
		"story": "A girl in a blue jersey runs towards a football while a girl in a white jersey runs alongside and challenges her for it.",
		"encoding_questions": [
			{
				"question": "Who runs toward the football in the scene?",
				"options": ["girls", "boys", "men", "girl and boy"],
				"answer": "girls"
			},
			{
				"question": "What are the girls doing with the ball?",
				"options": ["chasing", "catching", "kicking", "bouncing"],
				"answer": "chasing"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"boy slides for football",
					"man kicks football into goal",
					"goalkeeper catches football",
					"girls run toward football"
				],
				"answer": "girls run toward football"
			}
		]
	},
	"2347025": {
		"cue": "umbrella",
		"story": "A woman carries a baby on her back. The baby holds up a pink umbrella above them.",
		"encoding_questions": [
			{
				"question": "Who is holding the umbrella in the scene?",
				"options": ["woman", "girl", "man", "baby"],
				"answer": "baby"
			},
			{
				"question": "Where is the baby in relation to the mother?",
				"options": ["on back", "sitting on shoulders", "next to her", "in arms"],
				"answer": "on back"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"baby lies under umbrella",
					"woman holds umbrella over baby",
					"baby drags pink umbrella",
					"baby holds onto umbrella"
				],
				"answer": "baby holds onto umbrella"
			}
		]
	},
	"2347400": {
		"cue": "wine",
		"story": "Two men sit on a couch, each holding a wine glass near their faces and smelling the wine.",
		"encoding_questions": [
			{
				"question": "What are the men doing with the wine?",
				"options": ["sipping", "clinking", "smelling", "pouring"],
				"answer": "smelling"
			},
			{
				"question": "What are the men sitting on in the scene?",
				"options": ["couch", "table", "chairs", "bench"],
				"answer": "couch"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"men clink wine glasses",
					"men sip from wine glasses",
					"men smell wine glasses",
					"men grab wine bottles"
				],
				"answer": "men smell wine glasses"
			}
		]
	},
	"2348899": {
		"cue": "tie",
		"story": "A woman touches/holds the seated man's striped tie while he smiles. A man in a suit leans in and gestures toward the seated man during their conversation.",
		"encoding_questions": [
			{
				"question": "What is the woman doing?",
				"options": [
					"Pointing at a man",
					"Folding a tie",
					"Presenting a gift",
					"Touching the man's tie"
				],
				"answer": "Touching the man's tie"
			},
			{
				"question": "Where is the woman located relative to the man?",
				"options": ["up front", "at the back", "on the right", "on the left"],
				"answer": "on the right"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"man holds his striped tie",
					"woman touches man's striped tie",
					"woman gives man a striped tie",
					"man ties another man's striped tie"
				],
				"answer": "woman touches man's striped tie"
			}
		]
	},
	"2349475": {
		"cue": "blender",
		"story": "A man uses a bike to power a blender while a woman holds the lid of the blender filled with liquid.",
		"encoding_questions": [
			{
				"question": "Which part of the blender is the woman holding?",
				"options": ["Base", "Lid", "Glass", "Handle"],
				"answer": "Lid"
			},
			{
				"question": "Where is the man positioned relative to the blender?",
				"options": [
					"behind it",
					"to the left of it",
					"to the right of it",
					"in front of it"
				],
				"answer": "to the left of it"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"woman opens blender lid",
					"woman cranks blender handle",
					"woman presses blender button",
					"woman holds onto blender"
				],
				"answer": "woman holds onto blender"
			}
		]
	},
	"2350974": {
		"cue": "drink",
		"story": "A child drinks from a bottle while standing next to a red car. The child rests a hand on the car door.",
		"encoding_questions": [
			{
				"question": "What is the child's hand touching?",
				"options": ["grey motorcycle", "red motorcycle", "red car", "grey car"],
				"answer": "red car"
			},
			{
				"question": "What is the child in between?",
				"options": [
					"blue motorcycle and red motorcycle",
					"red car and blue motorcycle",
					"grey car and red motorcycle",
					"blue car and red car"
				],
				"answer": "red car and blue motorcycle"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"adult drinks beside bus",
					"child drinks beside car",
					"adult drinks beside train",
					"child drinks beside stroller"
				],
				"answer": "child drinks beside car"
			}
		]
	},
	"2356125": {
		"cue": "luggage",
		"story": "Two uniformed women push/move large luggage along an airport conveyor belt, while two other uniformed staff stand nearby.",
		"encoding_questions": [
			{
				"question": "Where is the luggage being moved to?",
				"options": [
					"onto xray",
					"onto conveyor belt",
					"onto baggage cart",
					"off of xray"
				],
				"answer": "onto conveyor belt"
			},
			{
				"question": "How many uniformed staff are moving the luggage?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"staff load luggage onto a conveyor belt",
					"staff tag luggage at a counter",
					"staff load luggage onto a cart",
					"staff load luggage into an xray"
				],
				"answer": "staff load luggage onto a conveyor belt"
			}
		]
	},
	"2360001": {
		"cue": "clock",
		"story": "Two workers are lifting a large round clock onto a building facade, with one of them steadying it while the other attaches it to the bracket and weaves through a cable.",
		"encoding_questions": [
			{
				"question": "Where are the men?",
				"options": ["on roof edge", "on ground", "on scaffold", "on balcony"],
				"answer": "on scaffold"
			},
			{
				"question": "What are the workers doing to the clock?",
				"options": ["wiping it", "measuring it", "painting it", "raising it"],
				"answer": "raising it"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"workers wipe large clock face",
					"workers paint old clock",
					"workers lift large clock",
					"workers raise ladder up to clock"
				],
				"answer": "workers lift large clock"
			}
		]
	},
	"2362277": {
		"cue": "frisbee",
		"story": "A player in white runs while attempting to throw a frisbee. A player in red closely blocks him from throwing the frisbee.",
		"encoding_questions": [
			{
				"question": "How are the frisbee defender's arms positioned?",
				"options": [
					"both below waist",
					"both high above head",
					"one above ahead; the other below waist",
					"both out to the side"
				],
				"answer": "both out to the side"
			},
			{
				"question": "On which side of the defender is the thrower located?",
				"options": [
					"behind defender",
					"in front of defender",
					"on the right",
					"on the left"
				],
				"answer": "on the left"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"player runs towards frisbee",
					"player catches frisbee at waist",
					"player throws a frisbee",
					"player catches frisbee overhead"
				],
				"answer": "player throws a frisbee"
			}
		]
	},
	"2362704": {
		"cue": "bears",
		"story": "Two bears are eating pieces of a pumpkin on the ground. One bear has its face in the hollow pumpkin while the other eats a chunk nearby.",
		"encoding_questions": [
			{
				"question": "How many bears are in the scene?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			},
			{
				"question": "What are the bears doing with the pumpkin?",
				"options": ["sniffing", "pawing", "fighting over", "eating"],
				"answer": "eating"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"bears roll pumpkin",
					"bears sniff pumpkin",
					"bears eat pumpkin",
					"bears fight over pumpkin"
				],
				"answer": "bears eat pumpkin"
			}
		]
	},
	"2363971": {
		"cue": "petting",
		"story": "A woman pets a large dog in the foreground while another woman in a chair holds a child upside down on her lap. A man also pets the dog in the foreground. The scene takes place indoors.",
		"encoding_questions": [
			{
				"question": "Where does the petting occur in the scene?",
				"options": ["Living room", "Park", "Barn", "Sidewalk"],
				"answer": "Living room"
			},
			{
				"question": "What is the seated woman (in background) doing with the child?",
				"options": [
					"holding it upside down",
					"reading a book to it",
					"hugging it",
					"feeding it from plate"
				],
				"answer": "holding it upside down"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"woman pets dog indoors",
					"child pets horse outside",
					"child pets dog indoors",
					"woman pets cat outside"
				],
				"answer": "woman pets dog indoors"
			}
		]
	},
	"2366915": {
		"cue": "surfer",
		"story": "Two surfers ride along the same breaking wave as water sprays behind and around them.",
		"encoding_questions": [
			{
				"question": "How many surfers are riding the wave?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			},
			{
				"question": "How large is the wave relative to the surfers?",
				"options": [
					"as tall as them",
					"twice as tall",
					"three times as tall",
					"half as tall"
				],
				"answer": "as tall as them"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"two surfers ride a wave",
					"two surfers walk toward wave",
					"two surfers paddle toward wave",
					"one surfer rides a wave"
				],
				"answer": "two surfers ride a wave"
			}
		]
	},
	"2367132": {
		"cue": "video game",
		"story": "Two men are playing a video game while holding motion controllers and moving their arms.",
		"encoding_questions": [
			{
				"question": "How many men are playing in the scene?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			},
			{
				"question": "From THEIR point of view, in which hand(s) do the men hold the motion controllers?",
				"options": [
					"in left hand",
					"in both hands",
					"neither hand (on wrists)",
					"in right hand"
				],
				"answer": "in both hands"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"Sitting with Xbox controllers",
					"Playing on laptops",
					"Standing with motion controllers",
					"Watching a gameplay video"
				],
				"answer": "Standing with motion controllers"
			}
		]
	},
	"2369373": {
		"cue": "chef",
		"story": "A chef places a pizza into a wood-fired oven, which has the appearance of a Greek god's open mouth.",
		"encoding_questions": [
			{
				"question": "What is the appearance of the oven?",
				"options": ["brick dome", "stone arch", "metal box", "open mouth"],
				"answer": "open mouth"
			},
			{
				"question": "What is the chef placing into the oven?",
				"options": ["steak", "vegetable tray", "bread", "pizza"],
				"answer": "pizza"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"chef stokes oven flames",
					"chef pulls tray from oven",
					"chef loads bread into oven",
					"chef loads pizza into oven"
				],
				"answer": "chef loads pizza into oven"
			}
		]
	},
	"2370664": {
		"cue": "donuts",
		"story": "Two men and a woman are taking bites of donuts. They are close together outdoors, holding the donuts up to their mouths.",
		"encoding_questions": [
			{
				"question": "How many donuts are in the scene?",
				"options": ["two", "three", "four", "five"],
				"answer": "three"
			},
			{
				"question": "Where are the people located in the scene?",
				"options": ["restaurant", "kitchen", "living room", "street"],
				"answer": "street"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"people dip donuts in coffee",
					"people hold donuts over eyes",
					"people bite into donuts",
					"man offers donut to woman"
				],
				"answer": "people bite into donuts"
			}
		]
	},
	"2371471": {
		"cue": "motorcycle",
		"story": "Two motorcyclists are airborne on dirt bikes inside a building, performing jumps above a ramp.",
		"encoding_questions": [
			{
				"question": "Which of the motorcyclists is performing a handstand?",
				"options": ["one up front", "both", "one at the back", "neither"],
				"answer": "one up front"
			},
			{
				"question": "What is nearest to the motorcyclists?",
				"options": ["dirt ramp", "concrete ramp", "grassy ground", "asphalt road"],
				"answer": "dirt ramp"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"motorcyclists pop a wheelie",
					"motorcyclists speed across road",
					"motorcyclists drive on dirt track",
					"motorcyclists jump over ramp"
				],
				"answer": "motorcyclists jump over ramp"
			}
		]
	},
	"2374670": {
		"cue": "truck",
		"story": "A red truck sprays water onto a dirt road through nozzles at the back. A man is climbing on the back of the truck while it operates.",
		"encoding_questions": [
			{
				"question": "What vehicle sprays water in the scene?",
				"options": ["grey van", "red tractor", "grey tractor", "red truck"],
				"answer": "red truck"
			},
			{
				"question": "What is the truck spraying?",
				"options": ["sand", "water", "asphalt", "fertilizer"],
				"answer": "water"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"truck pulls broken car",
					"truck sprays water",
					"truck dumps gravel onto road",
					"truck fills water tank"
				],
				"answer": "truck sprays water"
			}
		]
	},
	"2379478": {
		"cue": "milk",
		"story": "Two babies are lying on a bed, each drinking from a milk bottle.",
		"encoding_questions": [
			{
				"question": "What is the position of the babies?",
				"options": ["lying on couch", "lying in crib", "lying on bed", "sitting on bed"],
				"answer": "lying on bed"
			},
			{
				"question": "In what position are the babies drinking milk?",
				"options": ["sitting up", "lying on stomach", "lying on back", "lying on side"],
				"answer": "lying on back"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"two babies drink from milk bottles",
					"one baby drinks from a milk bottle",
					"one baby reaches for milk bottle",
					"two babies reach for one milk bottle"
				],
				"answer": "two babies drink from milk bottles"
			}
		]
	},
	"2383555": {
		"cue": "boat",
		"story": "A woman sits in a bamboo boat holding a child on her lap. A woman behind her rows the boat through the water.",
		"encoding_questions": [
			{
				"question": "Who is holding the child in the boat?",
				"options": ["girl", "boy", "man", "woman"],
				"answer": "woman"
			},
			{
				"question": "What is the woman at the back doing in the boat?",
				"options": ["sitting", "waving", "rowing", "standing"],
				"answer": "rowing"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"child sits alone in boat",
					"man steps onto a boat",
					"two women row a boat",
					"woman holds child on boat"
				],
				"answer": "woman holds child on boat"
			}
		]
	},
	"2385550": {
		"cue": "tangerines",
		"story": "A boy and a girl each have a tangerine in their mouth and are eating it while facing the camera.",
		"encoding_questions": [
			{
				"question": "Where are the tangerines in the scene?",
				"options": ["in front of eyes", "in mouths", "in hands", "on head"],
				"answer": "in mouths"
			},
			{
				"question": "Which side of the frame is the boy on?",
				"options": ["in the back", "on the left", "in the front", "on the right"],
				"answer": "on the left"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"children pick tangerines from tree",
					"children peel tangerines",
					"children hold tangerines in hands",
					"children have tangerines in mouths"
				],
				"answer": "children have tangerines in mouths"
			}
		]
	},
	"2386442": {
		"cue": "teeth",
		"story": "A woman, a child, and a man are each brushing their teeth with toothbrushes. They are facing the camera while brushing. The man is wearing a purple shirt, the woman is wearing a striped shirt, while the child is wearing a pink checkered shirt.",
		"encoding_questions": [
			{
				"question": "Who is brushing their teeth in the scene?",
				"options": [
					"man and woman",
					"man and two children",
					"man, woman, and child",
					"child and two women"
				],
				"answer": "man, woman, and child"
			},
			{
				"question": "Which position is the child in?",
				"options": ["in the middle", "on the left", "at the back", "on the right"],
				"answer": "in the middle"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"family brushes teeth together",
					"child flosses teeth carefully",
					"woman brushes a child's teeth",
					"family checks teeth in mirror"
				],
				"answer": "family brushes teeth together"
			}
		]
	},
	"2387122": {
		"cue": "polar bear",
		"story": "A polar bear swims in the water and presses against the enclosure glass while a woman on the other side takes a photo of it.",
		"encoding_questions": [
			{
				"question": "Where is the polar bear located in the scene?",
				"options": ["on rocks", "on sand", "on ice", "in water"],
				"answer": "in water"
			},
			{
				"question": "What is the polar bear doing next to the enclosure edge?",
				"options": [
					"pressing on glass enclosure",
					"sitting on snowy ground",
					"diving underwater",
					"swimming away from glass enclosure"
				],
				"answer": "pressing on glass enclosure"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"polar bear presses on glass",
					"polar bear swims away from glass",
					"polar bear dives underwater",
					"polar bear sits on snowy ground"
				],
				"answer": "polar bear presses on glass"
			}
		]
	},
	"2397102": {
		"cue": "cake",
		"story": "A woman and a man are cutting a decorated wedding cake together while the man holds a bottle in his other hand.",
		"encoding_questions": [
			{
				"question": "What are the couple doing with the cake?",
				"options": [
					"serving it",
					"cutting it",
					"posing next to it",
					"feeding each other"
				],
				"answer": "cutting it"
			},
			{
				"question": "What is the man holding besides the cake knife?",
				"options": ["paper plate", "present", "beer bottle", "wine glass"],
				"answer": "beer bottle"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"couple kisses beside cake",
					"couple cuts cake together",
					"couple poses with wedding cake",
					"couple feeds each other cake"
				],
				"answer": "couple cuts cake together"
			}
		]
	},
	"2401636": {
		"cue": "baby",
		"story": "A cat leans toward and sniffs a baby sitting beside it. A woman holds the cat and baby close while watching the baby.",
		"encoding_questions": [
			{
				"question": "Who is looking at the cat in the scene?",
				"options": ["woman", "man", "girl", "baby"],
				"answer": "baby"
			},
			{
				"question": "What is the mom holding in her arms?",
				"options": ["baby", "dog and cat", "baby and cat", "baby and dog"],
				"answer": "baby and cat"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"baby looks at cat",
					"woman raises up cat",
					"cat licks woman's hand",
					"cat sleeps beside baby"
				],
				"answer": "baby looks at cat"
			}
		]
	},
	"2411268": {
		"cue": "apple",
		"story": "A child reaches up to pick a green apple from a tree while holding a red bag for collecting fruit.",
		"encoding_questions": [
			{
				"question": "What is the child holding while picking fruit?",
				"options": ["bag", "basket", "bucket", "box"],
				"answer": "bag"
			},
			{
				"question": "Where is the fruit branch relative to the child?",
				"options": ["above head", "below head", "near ground", "at head level"],
				"answer": "above head"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"child picks apple from tree",
					"child puts apple into bag",
					"child picks apple up from the ground",
					"child bites into apple"
				],
				"answer": "child picks apple from tree"
			}
		]
	},
	"2412687": {
		"cue": "dog",
		"story": "A person holds out a red frisbee toward a dog. The dog bites onto the frisbee with its mouth.",
		"encoding_questions": [
			{
				"question": "What is the dog biting onto in the scene?",
				"options": ["red boomerang", "red bone", "red ball", "red frisbee"],
				"answer": "red frisbee"
			},
			{
				"question": "What is the main action of the human in the scene?",
				"options": [
					"picking up frisbee",
					"holding frisbee",
					"catching frisbee",
					"throwing frisbee"
				],
				"answer": "holding frisbee"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"dog ignores offered frisbee",
					"man throws frisbee towards dog",
					"dog bites onto frisbee",
					"dog catches frisbee midair"
				],
				"answer": "dog bites onto frisbee"
			}
		]
	},
	"2356991": {
		"cue": "baseball",
		"story": "A player slides headfirst toward a base while another player in a glove catches a thrown ball beside the base.",
		"encoding_questions": [
			{
				"question": "How is the player on the left reaching the base?",
				"options": [
					"sliding headfirst",
					"sliding on knees",
					"sliding feetfirst",
					"running towards it"
				],
				"answer": "sliding headfirst"
			},
			{
				"question": "What is the current action of the gloved player on the base?",
				"options": [
					"throwing the ball",
					"catching the ball",
					"dropping the ball",
					"tagging the runner"
				],
				"answer": "catching the ball"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"player runs towards base",
					"gloved player holds a ball",
					"player slides headfirst to base",
					"player slides feetfirst toward base"
				],
				"answer": "player slides headfirst to base"
			}
		]
	},
	"2385851": {
		"cue": "suitcase",
		"story": "Two men walk along a covered walkway while each carries a large red suitcase.",
		"encoding_questions": [
			{
				"question": "What are the men doing with the suitcases?",
				"options": ["pulling them", "carrying them", "opening them", "stacking them"],
				"answer": "carrying them"
			},
			{
				"question": "Where are the men?",
				"options": [
					"walking in an airport terminal",
					"walking along a train platform",
					"walking into a hotel lobby",
					"walking under a covered walkway"
				],
				"answer": "walking under a covered walkway"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"men carry suitcases on shoulders",
					"man opens suitcases outside",
					"men pull suitcases behind them",
					"men stack suitcases on cart"
				],
				"answer": "men carry suitcases on shoulders"
			}
		]
	},
	"2394020": {
		"cue": "horse ride",
		"story": "Two horseriders are riding horses along the sandy shore beside the water. Both horses are patchy while the riders are wearing cowboy hats. The weather is sunny and the water is calm.",
		"encoding_questions": [
			{
				"question": "Where is the scene taking place?",
				"options": ["along ocean", "along stream", "along beach", "along open field"],
				"answer": "along beach"
			},
			{
				"question": "What are the riders wearing on their heads?",
				"options": ["helmets", "baseball caps", "sun hats", "cowboy hats"],
				"answer": "cowboy hats"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"people ride horses through forest",
					"people ride horses along beach",
					"people ride horses through field",
					"people ride horses on road"
				],
				"answer": "people ride horses along beach"
			}
		]
	},
	"2406346": {
		"cue": "circus",
		"story": "One elephant holds the tail of another elephant, ahead of it, with its trunk. The elephant up front has a star on its back. A handler walks beside the elephants holding a stick and leading the elephants forward.",
		"encoding_questions": [
			{
				"question": "Which elephant is the man/handler closest to?",
				"options": [
					"back elephant",
					"neither elephant",
					"both elephants",
					"front elephant"
				],
				"answer": "back elephant"
			},
			{
				"question": "What is one elephant doing to the other?",
				"options": [
					"spraying it with water",
					"holding its tail",
					"touching its trunks",
					"nothing; its trunk is extended above its head without interaction"
				],
				"answer": "holding its tail"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"circus elephants walk on street",
					"circus elephants perform tricks",
					"circus elephants washed by handler",
					"circus elephants stand on pedestals"
				],
				"answer": "circus elephants walk on street"
			}
		]
	},
	"2408717": {
		"cue": "surfboard",
		"story": "Four surfers walk along the shoreline while carrying their surfboards. Waves roll in front of them as they head down towards the beach.",
		"encoding_questions": [
			{
				"question": "How many surfers are in the scene?",
				"options": ["two", "three", "four", "five"],
				"answer": "four"
			},
			{
				"question": "What are the colors of the surfboards in the scene?",
				"options": [
					"red and green",
					"blue and yellow",
					"white and yellow",
					"white and red"
				],
				"answer": "white and yellow"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"surfers walk towards water with surfboards",
					"surfers stand on surfboards on the beach",
					"surfers place surfboards into water",
					"surfers lie on surfboards"
				],
				"answer": "surfers walk towards water with surfboards"
			}
		]
	},
	"2409918": {
		"cue": "elephant",
		"story": "Two men are riding elephants while they are swimming in moderately deep water. One elephant is eating plants with its trunk.",
		"encoding_questions": [
			{
				"question": "What is the elephant on the right doing with its trunk?",
				"options": [
					"reaching forward",
					"grabbing log",
					"spraying water",
					"eating plants"
				],
				"answer": "eating plants"
			},
			{
				"question": "Where are the elephants in the scene?",
				"options": [
					"walking on land",
					"splashing in puddle",
					"swimming in water",
					"standing in mud"
				],
				"answer": "swimming in water"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"elephants drink water",
					"elephants splash riders",
					"elephants swim in water",
					"elephants walk across savannah"
				],
				"answer": "elephants swim in water"
			}
		]
	},
	"2410309": {
		"cue": "laptop",
		"story": "A woman sits on a couch using a laptop on her lap. A baby beside her touches and uses another open laptop.",
		"encoding_questions": [
			{
				"question": "What is the woman using while sitting on the couch?",
				"options": ["phone", "book", "laptop", "tablet"],
				"answer": "laptop"
			},
			{
				"question": "How many of these electronic devices are visible in the scene?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			}
		],
		"decoding_questions": [
			{
				"question": "Which description best matches the image?",
				"options": [
					"baby touches laptop mouse",
					"woman closes laptop lid",
					"woman and baby use laptops",
					"man types on laptop keyboard"
				],
				"answer": "woman and baby use laptops"
			}
		]
	}
}
