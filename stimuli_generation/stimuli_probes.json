{
	"150472": {
		"cue": "pizza",
		"story": "Two women lean in with open mouths toward a large slice of pizza on a paper plate, each taking a bite from it.",
		"encoding_questions": [
			{
				"question": "How many women are in the scene?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			},
			{
				"question": "What are the women doing with the pizza?",
				"options": ["biting it", "cutting it", "holding it", "photographing it"],
				"answer": "biting it"
			},
			{
				"question": "Where is the pizza slice?",
				"options": ["on paper plate", "in pizza box", "on metal tray", "on table"],
				"answer": "on paper plate"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"women bite pizza slice",
					"women photograph pizza slice",
					"women cut large pizza",
					"woman carries pizza box"
				],
				"answer": "women bite pizza slice"
			}
		]
	},
	"2344622": {
		"cue": "cat",
		"story": "A person is typing on a keyboard. A cat is resting its head next to the person's arm on top of a blue blanket, near the keyboard.",
		"encoding_questions": [
			{
				"question": "Where is the cat positioned relative to other scene elements?",
				"options": [
					"next to keyboard",
					"on keyboard",
					"under blanket",
					"on person's arm"
				],
				"answer": "next to keyboard"
			},
			{
				"question": "What is the cat resting its head on?",
				"options": ["person's arm", "keyboard edge", "plush toy", "blue blanket"],
				"answer": "blue blanket"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"cat lies on blanket",
					"cat lies on person's arm",
					"cat paws at keyboard",
					"cat paws at blanket"
				],
				"answer": "cat lies on blanket"
			}
		]
	},
	"2345035": {
		"cue": "football",
		"story": "A girl in a blue jersey runs towards a football while a girl in a white jersey runs alongside and challenges her for it.",
		"encoding_questions": [
			{
				"question": "Who runs toward the football in the scene?",
				"options": ["girls", "boys", "men", "girl and boy"],
				"answer": "girls"
			},
			{
				"question": "What are the girls doing with the ball?",
				"options": ["chasing", "kicking", "catching", "bouncing"],
				"answer": "chasing"
			},
			{
				"question": "What color jersey is the leading girl wearing in the football chase?",
				"options": ["blue", "white", "red", "black"],
				"answer": "blue"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"girls run toward football",
					"man kicks football into goal",
					"boy slides for football",
					"goalkeeper catches football"
				],
				"answer": "girls run toward football"
			}
		]
	},
	"2347025": {
		"cue": "umbrella",
		"story": "A woman carries a baby on her back. The baby holds up a pink umbrella above them.",
		"encoding_questions": [
			{
				"question": "Who is holding the umbrella in the scene?",
				"options": ["baby", "woman", "man", "girl"],
				"answer": "baby"
			},
			{
				"question": "What color is the umbrella in the scene?",
				"options": ["pink", "blue", "yellow", "black"],
				"answer": "pink"
			},
			{
				"question": "Where is the baby being carried?",
				"options": ["on back", "in arms", "in stroller", "on shoulders"],
				"answer": "on back"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"baby holds onto umbrella",
					"woman holds umbrella over baby",
					"baby drags pink umbrella",
					"baby lies under umbrella"
				],
				"answer": "baby holds onto umbrella"
			}
		]
	},
	"2347400": {
		"cue": "wine",
		"story": "Two men sit on a couch, each holding a wine glass near their faces and smelling the wine.",
		"encoding_questions": [
			{
				"question": "How many men are in the scene?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			},
			{
				"question": "What are the men doing with the wine?",
				"options": ["smelling", "sipping", "pouring", "clinking"],
				"answer": "smelling"
			},
			{
				"question": "What are the men sitting on in the scene?",
				"options": ["couch", "bench", "table", "chairs"],
				"answer": "couch"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"men smell wine glasses",
					"men clink wine glasses",
					"men sip from wine glasses",
					"men grab wine bottles"
				],
				"answer": "men smell wine glasses"
			}
		]
	},
	"2348899": {
		"cue": "tie",
		"story": "A woman touches/holds the seated man's striped tie while he smiles. A man in a suit leans in and gestures toward the seated man during their conversation.",
		"encoding_questions": [
			{
				"question": "What is the woman doing to the man's tie?",
				"options": ["holding it", "crumpling it", "tying it", "folding it"],
				"answer": "holding it"
			},
			{
				"question": "From your point of view, where is the standing man in relation to the seated man?",
				"options": ["right of", "left of", "behind", "in front of"],
				"answer": "left of"
			},
			{
				"question": "What is the standing man doing?",
				"options": [
					"gesturing toward seated man",
					"looking at standing woman",
					"looking at tie",
					"looking away from the sitting man"
				],
				"answer": "gesturing toward seated man"
			},
			{
				"question": "From your point of view, where is the woman in the scene?",
				"options": ["on the left", "on the right", "at the back", "up front"],
				"answer": "on the right"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"woman touches man's tie",
					"man holds his striped tie",
					"man ties another man's tie",
					"woman gives man a tie"
				],
				"answer": "woman touches man's tie"
			}
		]
	},
	"2349475": {
		"cue": "blender",
		"story": "A man uses a bike to power a blender while a woman holds the lid of the blender filled with liquid.",
		"encoding_questions": [
			{
				"question": "Who holds the blender lid in the scene?",
				"options": ["woman", "man", "child", "worker"],
				"answer": "woman"
			},
			{
				"question": "From your point of view, where is the man powering the blender relative to it?",
				"options": [
					"behind it",
					"in front of it",
					"to the left of it",
					"to the right of it"
				],
				"answer": "to the left of it"
			},
			{
				"question": "What is the color of the blender's contents?",
				"options": ["yellow", "red", "purple", "pink"],
				"answer": "yellow"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"woman holds onto blender",
					"woman presses blender button",
					"woman opens blender lid",
					"woman cranks blender handle"
				],
				"answer": "woman holds onto blender"
			}
		]
	},
	"2350974": {
		"cue": "drink",
		"story": "A child drinks from a bottle while standing next to a red car. The child rests a hand on the car door.",
		"encoding_questions": [
			{
				"question": "What is the child standing beside?",
				"options": ["red car", "red motorcycle", "grey car", "grey motorcycle"],
				"answer": "red car"
			},
			{
				"question": "What is the child's hand against?",
				"options": ["car door", "car roof", "car window", "side mirror"],
				"answer": "car door"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"child drinks beside car",
					"adult drinks beside bus",
					"child drinks beside stroller",
					"adult drinks beside train"
				],
				"answer": "child drinks beside car"
			}
		]
	},
	"2356125": {
		"cue": "luggage",
		"story": "Two uniformed women push/move large luggage along an airport conveyor belt, while two other uniformed staff stand nearby.",
		"encoding_questions": [
			{
				"question": "Where is the luggage being moved to?",
				"options": [
					"onto conveyor belt",
					"onto baggage cart",
					"onto xray",
					"off of xray"
				],
				"answer": "onto conveyor belt"
			},
			{
				"question": "How many uniformed staff are visible in the scene?",
				"options": ["two", "three", "four", "five"],
				"answer": "four"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"staff load luggage onto conveyor belt",
					"staff scan luggage in an xray",
					"staff load luggage onto a cart",
					"staff tag luggage at a counter"
				],
				"answer": "staff load luggage onto conveyor belt"
			}
		]
	},
	"2360001": {
		"cue": "clock",
		"story": "Two workers are lifting a large round clock onto a building facade, with one of them steadying it while the other attaches it to the bracket and weaves through a cable.",
		"encoding_questions": [
			{
				"question": "Which part of the building is the clock positioned onto?",
				"options": ["pole", "doorway", "balcony", "roof edge"],
				"answer": "pole"
			},
			{
				"question": "What are the workers doing to the clock?",
				"options": ["raising", "wiping", "painting", "measuring"],
				"answer": "raising"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"workers lift large clock",
					"workers wipe large clock face",
					"workers paint old clock",
					"workers raise ladder up to clock"
				],
				"answer": "workers lift large clock"
			}
		]
	},
	"2362277": {
		"cue": "frisbee",
		"story": "A player in white runs while attempting to throw a frisbee. A player in red closely blocks him from throwing the frisbee.",
		"encoding_questions": [
			{
				"question": "What is the player wearing white doing to the frisbee?",
				"options": ["throwing", "catching", "picking up", "blocking"],
				"answer": "throwing"
			},
			{
				"question": "From your position, how is the frisbee defender positioned relative to the thrower?",
				"options": [
					"standing to the right of",
					"running ahead to the left",
					"running towards to the right",
					"standing in front of"
				],
				"answer": "standing to the right of"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"player throws a frisbee",
					"player runs towards frisbee",
					"player catches frisbee overhead",
					"player catches frisbee at waist"
				],
				"answer": "player throws a frisbee"
			}
		]
	},
	"2362704": {
		"cue": "bears",
		"story": "Two bears are eating pieces of a pumpkin on the ground. One bear has its face in the hollow pumpkin while the other eats a chunk nearby.",
		"encoding_questions": [
			{
				"question": "How many bears are in the scene?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			},
			{
				"question": "What are the bears doing with the pumpkin?",
				"options": ["eating", "sniffing", "pawing", "fighting over"],
				"answer": "eating"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"bears eat pumpkin",
					"bears sniff pumpkin",
					"bears paw at pumpkin",
					"bears fight over pumpkin"
				],
				"answer": "bears eat pumpkin"
			}
		]
	},
	"2363971": {
		"cue": "petting",
		"story": "A woman pets a large dog in the foreground while another woman in a chair holds a child upside down on her lap. A man also pets the dog in the foreground. The scene takes place indoors.",
		"encoding_questions": [
			{
				"question": "Where does the petting occur in the scene?",
				"options": ["indoors", "outdoors", "street", "park"],
				"answer": "indoors"
			},
			{
				"question": "What is the seated woman (in background) doing with the child?",
				"options": [
					"holding it upside down",
					"feeding it from bowl",
					"hugging it",
					"reading a book to it"
				],
				"answer": "holding it upside down"
			},
			{
				"question": "How many people are in the scene?",
				"options": ["two", "three", "four", "five"],
				"answer": "four"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"woman pets dog indoors",
					"woman pets cat outside",
					"child pets horse outside",
					"child pets dog indoors"
				],
				"answer": "woman pets dog indoors"
			}
		]
	},
	"2366915": {
		"cue": "surfer",
		"story": "Two surfers ride along the same breaking wave as water sprays behind and around them.",
		"encoding_questions": [
			{
				"question": "How many surfers are riding the wave?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			},
			{
				"question": "What is the main action in the scene?",
				"options": ["surfing", "paddling", "walking", "standing"],
				"answer": "surfing"
			},
			{
				"question": "How large is the wave relative to the surfers?",
				"options": [
					"half as tall",
					"as tall as them",
					"twice as tall",
					"three times as tall"
				],
				"answer": "as tall as them"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"two surfers ride a wave",
					"two surfers paddle toward wave",
					"one surfer rides a wave",
					"two surfers walk toward wave"
				],
				"answer": "two surfers ride a wave"
			}
		]
	},
	"2367132": {
		"cue": "video game",
		"story": "Two men are playing a video game while holding motion controllers and moving their arms.",
		"encoding_questions": [
			{
				"question": "How many men are playing in the scene?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			},
			{
				"question": "From your point of view, in which hand do the men hold the controllers?",
				"options": [
					"in right hand",
					"in left hand",
					"in both hands",
					"neither hand; on wrists"
				],
				"answer": "in both hands"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"men play video game with motion controllers",
					"men watch video game on TV",
					"men play video game with xbox controllers",
					"men play board game at table"
				],
				"answer": "men play video game with motion controllers"
			}
		]
	},
	"2369373": {
		"cue": "chef",
		"story": "A chef places a pizza into a wood-fired oven, which has the appearance of a Greek god's open mouth.",
		"encoding_questions": [
			{
				"question": "What is the appearance of the oven?",
				"options": ["open mouth", "stone arch", "metal box", "brick dome"],
				"answer": "open mouth"
			},
			{
				"question": "What is the chef placing into the oven?",
				"options": ["bread", "steak", "vegetable tray", "pizza"],
				"answer": "pizza"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"chef loads pizza into oven",
					"chef loads bread into oven",
					"chef pulls tray from oven",
					"chef stokes oven flames"
				],
				"answer": "chef loads pizza into oven"
			}
		]
	},
	"2370664": {
		"cue": "donuts",
		"story": "Two men and a woman are taking bites of donuts. They are close together outdoors, holding the donuts up to their mouths.",
		"encoding_questions": [
			{
				"question": "How many people are biting donuts in the scene?",
				"options": ["two", "three", "four", "five"],
				"answer": "three"
			},
			{
				"question": "Where are the people located in the scene?",
				"options": ["street", "living room", "restaurant", "kitchen"],
				"answer": "street"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"people bite into donuts",
					"people dip donuts in coffee",
					"man offers donut to woman",
					"people hold donuts over eyes"
				],
				"answer": "people bite into donuts"
			}
		]
	},
	"2371471": {
		"cue": "motorcycle",
		"story": "Two motorcyclists are airborne on dirt bikes inside a building, performing jumps above a ramp.",
		"encoding_questions": [
			{
				"question": "Which of the motorcyclists is performing a handstand?",
				"options": ["one up front", "one at the back", "both", "neither"],
				"answer": "one up front"
			},
			{
				"question": "What is nearest to the motorcyclists?",
				"options": ["dirt ramp", "asphalt road", "grass patch", "concrete ground"],
				"answer": "dirt ramp"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"motorcyclists jump over ramp",
					"motorcyclists drive on road",
					"motorcyclists pop a wheelie",
					"motorcyclists speed across road"
				],
				"answer": "motorcyclists jump over ramp"
			}
		]
	},
	"2374670": {
		"cue": "truck",
		"story": "A red truck sprays water onto a dirt road through nozzles at the back. A man is climbing on the back of the truck while it operates.",
		"encoding_questions": [
			{
				"question": "What vehicle sprays water in the scene?",
				"options": ["red truck", "red tractor", "grey van", "grey tractor"],
				"answer": "red truck"
			},
			{
				"question": "What is the truck spraying?",
				"options": ["water", "sand", "fertilizer", "asphalt"],
				"answer": "water"
			},
			{
				"question": "Where is the (actively moving) man positioned relative to the truck?",
				"options": ["back", "roof", "side", "front"],
				"answer": "back"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"truck sprays water",
					"truck dumps gravel onto road",
					"truck pulls broken car",
					"truck fills water tank"
				],
				"answer": "truck sprays water"
			}
		]
	},
	"2379478": {
		"cue": "milk",
		"story": "Two babies are lying on a bed, each drinking from a milk bottle.",
		"encoding_questions": [
			{
				"question": "What is the position of the babies?",
				"options": ["lying on bed", "sitting on bed", "lying in crib", "lying on couch"],
				"answer": "lying on bed"
			},
			{
				"question": "What is the position of the babies?",
				"options": ["lying on stomach", "lying on back", "lying on side", "sitting up"],
				"answer": "lying on back"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"two babies drink from milk bottles",
					"one baby drinks from a milk bottle",
					"one baby reaches for milk bottle",
					"two babies reach for milk bottle"
				],
				"answer": "two babies drink from milk bottles"
			}
		]
	},
	"2383555": {
		"cue": "boat",
		"story": "A woman sits in a bamboo boat holding a child on her lap. A woman behind her rows the boat through the water.",
		"encoding_questions": [
			{
				"question": "Who is holding the child in the boat?",
				"options": ["woman", "man", "girl", "boy"],
				"answer": "woman"
			},
			{
				"question": "What is the woman at the back doing in the boat?",
				"options": ["rowing", "standing", "sleeping", "waving"],
				"answer": "rowing"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"woman holds child on boat",
					"two women row a boat",
					"child sits alone in boat",
					"man steps onto a boat"
				],
				"answer": "woman holds child on boat"
			}
		]
	},
	"2385550": {
		"cue": "tangerines",
		"story": "A boy and a girl each have a tangerine in their mouth and are eating it while facing the camera.",
		"encoding_questions": [
			{
				"question": "Which child has a tangerine in their mouth?",
				"options": ["boy", "girl", "both", "neither"],
				"answer": "both"
			},
			{
				"question": "Where are the tangerines placed in the scene?",
				"options": ["in mouths", "in hands", "on head", "in front of eyes"],
				"answer": "in mouths"
			},
			{
				"question": "From your point of view, where is the boy in the scene?",
				"options": ["on the left", "on the right", "in the back", "in the front"],
				"answer": "on the left"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"children have tangerines in mouths",
					"children peel tangerines",
					"children hold tangerines in hands",
					"children pick tangerines from tree"
				],
				"answer": "children have tangerines in mouths"
			}
		]
	},
	"2386442": {
		"cue": "teeth",
		"story": "A woman, a child, and a man are each brushing their teeth with toothbrushes. They are facing the camera while brushing. The man is wearing a purple shirt, the woman is wearing a striped shirt, while the child is wearing a pink checkered shirt.",
		"encoding_questions": [
			{
				"question": "Who is brushing their teeth in the scene?",
				"options": [
					"man and two children",
					"man and woman",
					"child and two women",
					"man, woman, and child"
				],
				"answer": "man, woman, and child"
			},
			{
				"question": "From your point of view, where is the child in the scene?",
				"options": ["in the middle", "on the left", "on the right", "at the back"],
				"answer": "in the middle"
			},
			{
				"question": "What colored shirt is the man wearing?",
				"options": ["purple", "striped", "pink checkered", "green"],
				"answer": "purple"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"family brushes teeth together",
					"child flosses teeth carefully",
					"family checks teeth in mirror",
					"woman brushes a child's teeth"
				],
				"answer": "family brushes teeth together"
			}
		]
	},
	"2387122": {
		"cue": "polar bear",
		"story": "A polar bear swims in the water and presses against the enclosure glass while a woman on the other side takes a photo of it.",
		"encoding_questions": [
			{
				"question": "Where is the polar bear located in the scene?",
				"options": ["in water", "on ice", "on rocks", "on sand"],
				"answer": "in water"
			},
			{
				"question": "What is the woman doing?",
				"options": [
					"taking a photo",
					"feeding the bear",
					"wiping her glasses",
					"pointing to bear"
				],
				"answer": "taking a photo"
			},
			{
				"question": "What is the polar bear doing next to the enclosure edge?",
				"options": [
					"pressing on glass enclosure",
					"swimming away from glass enclosure",
					"sitting on snowy ground",
					"diving underwater"
				],
				"answer": "pressing on glass enclosure"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"polar bear presses on glass",
					"polar bear swims away from glass",
					"polar bear sits on snowy ground",
					"polar bear dives underwater"
				],
				"answer": "polar bear presses on glass"
			}
		]
	},
	"2397102": {
		"cue": "cake",
		"story": "A woman and a man are cutting a decorated wedding cake together while the man holds a bottle in his other hand.",
		"encoding_questions": [
			{
				"question": "What are the couple doing with the cake?",
				"options": [
					"cutting it",
					"feeding each other",
					"posing next to it",
					"serving it"
				],
				"answer": "cutting it"
			},
			{
				"question": "What type of cake is being cut?",
				"options": ["wedding cake", "birthday cake", "cupcake tower", "fruit cake"],
				"answer": "wedding cake"
			},
			{
				"question": "What is the man holding besides the cake knife?",
				"options": ["beer bottle", "paper plate", "present", "wine glass"],
				"answer": "beer bottle"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"couple cuts cake together",
					"couple feeds each other cake",
					"couple poses with wedding cake",
					"couple kisses beside cake"
				],
				"answer": "couple cuts cake together"
			}
		]
	},
	"2401636": {
		"cue": "baby",
		"story": "A cat leans toward and sniffs a baby sitting beside it. A woman holds the cat and baby close while watching the baby.",
		"encoding_questions": [
			{
				"question": "Who is looking at the cat in the scene?",
				"options": ["baby", "woman", "man", "girl"],
				"answer": "baby"
			},
			{
				"question": "What is the mom holding in her arms?",
				"options": ["baby", "dog and cat", "baby and cat", "cat"],
				"answer": "baby and cat"
			},
			{
				"question": "Who holds the cat close to the baby?",
				"options": ["mother", "father", "nurse", "doctor"],
				"answer": "mother"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"baby looks at cat",
					"cat sleeps beside baby",
					"cat licks woman's hand",
					"woman raises up cat"
				],
				"answer": "baby looks at cat"
			}
		]
	},
	"2411268": {
		"cue": "apple",
		"story": "A child reaches up to pick a green apple from a tree while holding a red bag for collecting fruit.",
		"encoding_questions": [
			{
				"question": "What color are the apples in the scene?",
				"options": ["red", "green", "yellow", "multicolored"],
				"answer": "green"
			},
			{
				"question": "What is the child holding while picking fruit?",
				"options": ["bag", "bucket", "box", "basket"],
				"answer": "bag"
			},
			{
				"question": "Where is the fruit branch relative to the child?",
				"options": ["above head", "at head level", "below head", "near ground"],
				"answer": "above head"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"child picks apple from tree",
					"child bites into apple",
					"child picks apple up from the ground",
					"child puts apple into bag"
				],
				"answer": "child picks apple from tree"
			}
		]
	},
	"2412687": {
		"cue": "dog",
		"story": "A person holds out a red frisbee toward a dog. The dog bites onto the frisbee with its mouth.",
		"encoding_questions": [
			{
				"question": "What is the dog biting onto in the scene?",
				"options": ["red frisbee", "red ball", "red boomerang", "red bone"],
				"answer": "red frisbee"
			},
			{
				"question": "What is the main action of the human in the scene?",
				"options": [
					"holding frisbee",
					"throwing frisbee",
					"catching frisbee",
					"picking up frisbee"
				],
				"answer": "holding frisbee"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"dog bites onto frisbee",
					"dog catches frisbee midair",
					"dog ignores offered frisbee",
					"man throws frisbee towards dog"
				],
				"answer": "dog bites onto frisbee"
			}
		]
	},
	"2356991": {
		"cue": "baseball",
		"story": "A player slides headfirst toward a base while another player in a glove catches a thrown ball beside the base.",
		"encoding_questions": [
			{
				"question": "How is the player on the left reaching the base?",
				"options": [
					"sliding headfirst",
					"sliding feetfirst",
					"running towards it",
					"sliding on knees"
				],
				"answer": "sliding headfirst"
			},
			{
				"question": "What is the gloved player doing next to the base?",
				"options": ["catching ball", "dropping ball", "throwing ball", "tagging runner"],
				"answer": "catching ball"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"player slides headfirst to base",
					"player runs towards base",
					"player slides feetfirst toward base",
					"gloved player holds a ball"
				],
				"answer": "player slides headfirst to base"
			}
		]
	},
	"2385851": {
		"cue": "suitcase",
		"story": "Two men walk along a covered walkway while each carries a large red suitcase.",
		"encoding_questions": [
			{
				"question": "What are the men moving in the scene?",
				"options": [
					"red suitcases",
					"black suitcases",
					"blue suitcases",
					"brown suitcases"
				],
				"answer": "red suitcases"
			},
			{
				"question": "What are the men doing with the suitcases?",
				"options": ["carrying them", "opening them", "stacking them", "pulling them"],
				"answer": "carrying them"
			},
			{
				"question": "Where are the men walking?",
				"options": [
					"along covered walkway",
					"along train platform",
					"along airport terminal",
					"along hotel lobby"
				],
				"answer": "along covered walkway"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"men carry suitcases on shoulders",
					"men pull suitcases behind them",
					"men stack suitcases on cart",
					"man opens suitcases outside"
				],
				"answer": "men carry suitcases on shoulders"
			}
		]
	},
	"2394020": {
		"cue": "horse ride",
		"story": "Two horseriders are riding horses along the sandy shore beside the water. Both horses are patchy while the riders are wearing cowboy hats. The weather is sunny and the water is calm.",
		"encoding_questions": [
			{
				"question": "What do the horses look like?",
				"options": ["patchy", "black", "white", "brown"],
				"answer": "patchy"
			},
			{
				"question": "Where is the scene taking place?",
				"options": ["shore", "forest", "sunny road", "sunny field"],
				"answer": "shore"
			},
			{
				"question": "What are the riders wearing on their heads?",
				"options": ["cowboy hats", "helmets", "baseball caps", "sun hats"],
				"answer": "cowboy hats"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"people ride horses along shoreline",
					"people ride horses through forest",
					"people ride horses on road",
					"people ride horses through field"
				],
				"answer": "people ride horses along shoreline"
			}
		]
	},
	"2406346": {
		"cue": "circus",
		"story": "One elephant holds the tail of another elephant, ahead of it, with its trunk. The elephant up front has a star on its back. A handler walks beside the elephants holding a stick and leading the elephants forward.",
		"encoding_questions": [
			{
				"question": "Who leads the elephants forward in the scene?",
				"options": ["handler", "clown", "child", "rider"],
				"answer": "handler"
			},
			{
				"question": "What is the elephant up front tattooed with?",
				"options": ["star", "heart", "circle", "square"],
				"answer": "star"
			},
			{
				"question": "Which elephant is the handler closest to?",
				"options": [
					"front elephant",
					"back elephant",
					"both elephants",
					"neither elephant"
				],
				"answer": "back elephant"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"circus elephants walk on street",
					"circus elephants perform tricks",
					"circus elephants washed by handler",
					"circus elephants stand on pedestals"
				],
				"answer": "circus elephants walk on street"
			}
		]
	},
	"2408717": {
		"cue": "surfboard",
		"story": "Four surfers walk along the shoreline while carrying their surfboards. Waves roll in front of them as they head down towards the beach.",
		"encoding_questions": [
			{
				"question": "How many surfers are in the scene?",
				"options": ["two", "three", "four", "five"],
				"answer": "four"
			},
			{
				"question": "What are the colors of the surfboards in the scene?",
				"options": [
					"white and red",
					"white and yellow",
					"blue and yellow",
					"red and green"
				],
				"answer": "white and yellow"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"surfers walk towards water with surfboards",
					"surfers lie on surfboards",
					"surfers wax surfboards on beach",
					"surfers place surfboards into water"
				],
				"answer": "surfers walk towards water with surfboards"
			}
		]
	},
	"2409918": {
		"cue": "elephant",
		"story": "Two men are riding elephants while they are swimming in moderately deep water. One elephant is eating plants with its trunk.",
		"encoding_questions": [
			{
				"question": "Who is riding the elephants in the scene?",
				"options": ["two men", "two women", "one man, one child", "one man, one woman"],
				"answer": "two men"
			},
			{
				"question": "What is the elephant on the right doing with its trunk?",
				"options": [
					"eating plants",
					"spraying water",
					"reaching forward",
					"grabbing log"
				],
				"answer": "eating plants"
			},
			{
				"question": "Where are the elephants in the scene?",
				"options": [
					"swimming in water",
					"walking on land",
					"standing in mud",
					"splashing in puddle"
				],
				"answer": "swimming in water"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"elephants swim in water",
					"elephants drink water",
					"elephants splash riders",
					"elephants walk across savannah"
				],
				"answer": "elephants swim in water"
			}
		]
	},
	"2410309": {
		"cue": "laptop",
		"story": "A woman sits on a couch using a laptop on her lap. A baby beside her touches and uses another open laptop.",
		"encoding_questions": [
			{
				"question": "What device is the woman using on the couch?",
				"options": ["laptop", "tablet", "phone", "book"],
				"answer": "laptop"
			},
			{
				"question": "How many open laptops are in the scene?",
				"options": ["one", "two", "three", "four"],
				"answer": "two"
			}
		],
		"decoding_questions": [
			{
				"question": "Which scene matches the image?",
				"options": [
					"woman and baby use laptops",
					"woman closes laptop lid",
					"baby touches laptop mouse",
					"man types on laptop keyboard"
				],
				"answer": "woman and baby use laptops"
			}
		]
	}
}
